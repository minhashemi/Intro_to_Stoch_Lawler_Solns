% --------------------------------------------------------------
  % This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{book}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,hyperref,blkarray}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}

\hypersetup{
bookmarks=true,
unicode=true,
pdftitle={Jonathan Bown-Amin Hashemi}
}


\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{solution}
               {\let\oldqedsymbol=\qedsymbol
                \renewcommand{\qedsymbol}{$\square$}
                \begin{proof}[\bfseries\upshape Solution]}
               {\end{proof}
                \renewcommand{\qedsymbol}{\oldqedsymbol}}


\newcommand{\prb}[1]{\textbf{Exercise #1.}}

\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

\title{Solutions Manual for Gregory F. Lawler's \\ \emph{Introduction to Stochastic Processes}}%replace X with the appropriate number
\author{Jonathan Bown - Amin Hashemi}
\date{}

\maketitle

\part{}

\chapter{Finite Markov Chains}



%-------------
%      Notation for Exercises
%-------------
\begin{problem}{1.1}
\end{problem}


\begin{problem}{1.2}
Consider a Markov chain with state space {0,1} and transition matrix\\
\begin{center}
$\bf{P} = \begin{bmatrix}
    1/3 & 2/3 \\
    3/4 & 1/4 
\end{bmatrix}$
\end{center}
Assuming that the chain starts in state $0$ at time $n = 0$, what is the probability that it is in state 1 at time $n=3$?
\end{problem}
\begin{solution}
This is just some basic matrix multiplication. The chain starts in state 0 at time $n = 0$ so we will look at the first row of the matrix $\bf{P}^3$. 
\end{solution}


\begin{problem}{1.3}
\end{problem}
\begin{solution}

(a) We have that $P = \begin{bmatrix}
    0.4 & 0.2 & 0.4 \\
    0.6 & 0 & .4 \\
    0.2 & 0.5 & 0.3
\end{bmatrix}$
The matrix $P^n$ converges pretty quickly so you only need to use a power of say, 100. Using R gives the following: \\
\begin{center}
$P^{100} = \begin{bmatrix}
    0.3787879 & 0.2575758 & 0.3636364 \\
    0.3787879 & 0.2575758 & 0.3636364 \\
    0.3787879 & 0.2575758 & 0.3636364 
\end{bmatrix}$
\end{center} 
Thus the common row vector is \\
\begin{center}
$\pi = (0.3787879,0.2575758,0.3636364)$
\end{center}

(b) \\

(c)
\end{solution}

\begin{problem}{1.4}
\end{problem}
\begin{solution}
\end{solution}



\begin{problem}{1.5}
\end{problem}
\begin{solution}
(1) Recurrent classes: $\{0,1\}, \{2,4\}$. Transient class: $\{3,5\}$ \\
(2) To analyze large time behavior of the Markov chain on the class $R_{1} = \{0,1\}$, we need only to consider its matrix 
\begin{center}
$ \bf{P}_{\{0,1\}} = 
    \bordermatrix{ & 0 & 1 \cr
      0 & 0.5 & 0.5 \cr
      1 & 0.3 & 0.7 } \qquad
      $
\end{center}
Solving $\pi \bf{P}_{\{0,1\}} = \pi$ we get its invariant probability $\pi = (\frac{3}{8}, \frac{5}{8})$. Then $lim_{n \to \infty} P_{n}(0,0) = \frac{3}{8}$. \\

(3) To find $lim_{n \to \infty} P_{n}(5,0)$, we first find $lim_{n \to \infty} P_{n}(0,R_{1})$, the probability that the chain will be absorbed into $R_{1} = \{0,1\}$. Rearrange $P$ we can write it as 
\begin{center}
$ \bf{\tilde{P}}_{\{0,1\}} = 
    \bordermatrix{ & \{0,1\} & \{2,4\} & 3 & 5 \cr
      \{0,1\} & 1 & 0 & 0 & 0 \cr
      \{2,4\} & 0 & 1 & 0 & 0 \cr
      3 & 0.5 & 0.25 & 0 & 0.25 \cr
      5 & 0.2 & 0.2 & 0.2 & 0.4}  = \begin{bmatrix}
    I & 0 \\
    S & Q 
\end{bmatrix} $
      

      
\end{center}
Then it follows from $lim_{n \to \infty} \bf{\tilde{P}}^{n} = \begin{pmatrix} I & 0 \\ (I - Q)^{-1}S & 0 \end{pmatrix}$ (see Section 1.5) and 
\begin{center}
$(I - Q)^{-1}S = \frac{1}{11} * \begin{pmatrix} 7 & 4 \\ 6 & 5 \end{pmatrix}$ 
\end{center}
that $lim_{n \to \infty} P_{n}(5, R_{1}) = \frac{6}{11}$. Combining it with (2) we get $lim_{n \to \infty} P_{n}(5,0) = \frac{6}{11}* \frac{3}{8} = \frac{9}{44} = .2045$
\end{solution}


\begin{problem}{1.6}
\end{problem}
\begin{solution}
\end{solution}



\begin{problem}{1.7}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.8}
\end{problem}
\begin{solution}
\end{solution}

\begin{problem}{1.9}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.10}
\end{problem}
\begin{solution}
\end{solution}

\begin{problem}{1.11}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.12}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.13}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.14}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.15}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.16}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.17}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.18}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.19}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.20}
\end{problem}
\begin{solution}
\end{solution}


\begin{problem}{1.21}
\end{problem}
\begin{solution}
\end{solution}



\chapter{Countable Markov Chains}

\begin{problem}{2.1}
Consider the queueing model (Example 3 of Section 2.1). For which values of $p, q$ is the chain null recurrent, positive recurrent, transient? For the positive recurrent case give the limiting probability distribution $\pi$. What is the
average length of the queue in equilibrium? For the transient case, give $\alpha(x) =$ the probability starting at x of ever reaching state 0.
\end{problem}
\begin{solution}
The chain is positive Recurrent if $p < q$, null recurrent if $p = q$, and transient if $p > q$.
\end{solution}


\begin{problem}{2.2}
Consider the following Markov chain with state space $S = \{0, 1, \ldots\}$. A sequence of positive numbers $p_1, p_2, \ldots$ is given with
\[
\sum_{i=1}^{\infty} p_i = 1
\]
Whenever the chain reaches state $0$ it chooses a new state according to the $p_i$. Whenever the chain is at a state other than $0$ it proceeds deterministically, one step at a time, toward $0$. In other words, the chain has transition probability
\[
p(x, x-1) = 1, \quad x > 0,
\]
\[
p(0, x) = p_x, \quad x > 0.
\]

This is a recurrent chain since the chain keeps returning to $0$. Under what conditions on the $p_x$ is the chain positive recurrent? In this case, what is the limiting probability distribution $\pi$? [Hint: it may be easier to compute $\mathbb{E}(T)$ directly where $T$ is the time of first return to $0$ starting at $0$.]
\end{problem}
\begin{solution}
Let $T$ be the return time to state $0$ starting at $0$. Then, for every $x$, $\mathbb{P}(T = x) = p_x$ and so
\[
\mathbb{E}[T] = \sum_{x=1}^{\infty} x p_x.
\]
Therefore, state $0$ is positive recurrent if and only if
\[
\sum_{x=1}^{\infty} x p_x < \infty.
\]

In order to compute stationary distribution $\pi$, note that we have the following equations,
\[
\text{for } i > 0, \quad \pi_i = \pi_{i+1} + p_i \pi_0
\]
\[
\pi_0 = \pi_1
\]
\[
\pi_0 + \pi_1 + \cdots = 1
\]

Solving these gives
\[
\pi_0 = \left( \sum_{x=1}^{\infty} x p_x \right)^{-1},
\]
\[
\pi_i = \pi_0 \sum_{x=i}^{\infty} p_x, \quad \text{for } i > 0.
\]
\end{solution}

\begin{problem}{2.3}
Consider the Markov chain with state space $S = \{0, 1, 2, \ldots\}$ and transition probabilities:
\[
p(x, x+1) = 2/3; \qquad p(x, 0) = 1/3.
\]
Show that the chain is positive recurrent and give the limiting probability.
\end{problem}
\begin{solution}
Since the chain is irreducible (why?), in order to show that it is positive recurrent, we need to verify that it admits a stationary (probability) distribution $\pi$.

The distribution $\pi$ must satisfy
\[
\pi(0) = \sum_{j=0}^{\infty} \pi(j) \frac{1}{3} = \frac{1}{3} \sum_{x=0}^{\infty} \pi(x) = \frac{1}{3}
\]
and for $j \geq 1$:
\[
\pi(j) = \pi(j-1) \frac{2}{3}
\]
This gives
\[
\pi(j) = \left(\frac{2}{3}\right)^j \pi(0) = \frac{1}{3} \left(\frac{2}{3}\right)^j
\]

Since a stationary distribution exists, the chain is positive recurrent. Finally, note that the chain is aperiodic as well (there is a cycle of length one from $0$ to $0$). So, for every $i, j$
\[
\lim_{n \to \infty} p_n(i, j) = \pi(j) = \frac{1}{3} \left(\frac{2}{3}\right)^j
\]
\end{solution}


\begin{problem}{2.5}
Let $X_n$ be the Markov chain with state space $\mathbb{Z}$ and transition probability
\[
p(n, n+1) = p, \quad p(n, n-1) = 1-p,
\]
where $p > 1/2$. Assume $X_0 = 0$.

\begin{enumerate}
    \item[(a)] Let $Y = \min\{ X_0, X_1, \ldots \}$. What is the distribution of $Y$?
    \item[(b)] For positive integer $k$, let $T_k = \min\{ n : X_n = k \}$ and let $e(k) = \mathbb{E}[T_k]$. Explain why $e(k) = k e(1)$.
    \item[(c)] Find $e(1)$. (Hint: (b) might be helpful.)
    \item[(d)] Use (c) to give another proof that $e(1) = \infty$ if $p = 1/2$.
\end{enumerate}
\end{problem}
\begin{solution}
(a) Let $\mathbb{P}(Y \leq -k)$ be the probability that the minimum is at most $-k$. This is equal to the probability that the chain ever reaches $-k$, which for a biased random walk is:
\[
\mathbb{P}(T_{-k} < \infty \mid X_0 = 0) = \mathbb{P}(T_{-1} < \infty \mid X_0 = 0)^k = \left( \frac{1-p}{p} \right)^k.
\]
Thus,
\[
\mathbb{P}(Y = -k) = \mathbb{P}(Y \leq -k) - \mathbb{P}(Y \leq -(k+1)) = \left( \frac{1-p}{p} \right)^k - \left( \frac{1-p}{p} \right)^{k+1}.
\]

(b) Observe that
\[
e(k) = \mathbb{E}[T_k] = \mathbb{E}[T_1 + T_2 - T_1 + \ldots + T_k - T_{k-1}] = \sum_{j=1}^k \mathbb{E}[T_j - T_{j-1}].
\]
By translation invariance, $\mathbb{E}[T_j - T_{j-1}] = e(1)$ for all $j$, so $e(k) = k \cdot e(1)$.

(c) From state $0$, the chain moves to $1$ with probability $p$ and to $-1$ with probability $1-p$. So,
\[
e(1) = 1 + p \cdot 0 + (1-p) \cdot \mathbb{E}[T_1 \mid X_1 = -1].
\]
From $-1$, the chain must first return to $0$, then reach $1$, so:
\[
\mathbb{E}[T_1 \mid X_1 = -1] = e(1) + \mathbb{E}[T_0 \mid X_0 = -1] = e(1) + e(1) = 2e(1).
\]
Hence:
\[
e(1) = 1 + (1-p)(2e(1)) \implies e(1)(1 - 2(1-p)) = 1 \implies e(1) = \frac{1}{2p-1}.
\]

(d) If $p = \frac{1}{2}$, then:
\[
e(1) = \frac{1}{2p-1} = \frac{1}{0} = \infty.
\]
\end{solution}


\chapter{Continuous-Time Markov Chains}

\begin{problem}{3.1}
\end{problem}
\begin{solution}
\end{solution}




\chapter{Optimal Stopping}

\begin{problem}{4.1}
\end{problem}
\begin{solution}

To solve this, we use the convex function rule. Interpolating linearly we get:

\[
\begin{array}{c|ccccccccccc}
x & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline
f(x) & 0 & 2 & 4 & 3 & 10 & 0 & 6 & 4 & 3 & 3 & 0 \\
v(x) & 0 & 2.5 & 5 & 7.5 & 10 & 8.6 & 7.2 & 5.8 & 4.4 & \mathbf{3} & 0
\end{array}
\]

The optimal stopping rule is to stop at \( x = 4, 9 \) and continue otherwise (if you can).
\end{solution}


\begin{problem}{4.2}
\end{problem}
\begin{solution}

\begin{itemize}
  \item[(a)] 
  This is just
  \[
  E = \sum p(x)f(x) = \frac{210}{36} = \frac{35}{6} \approx 5.8333
  \]

  \item[(b)] The question itself is a hint. Instead of trying to compute \( v_n(x) \) we compute the expected payoff \( E_n \) for \( v_n \).

  \[
  E_1 = \sum_{x \ne 7} p(x) \cdot 12 = 10
  \]

  Given \( E_n \), we can compute \( E_{n+1} \) by

  \[
  E_{n+1} = \sum_{x \ne 7} p(x) \cdot \max(f(x), E_n)
  \]

  which gives:

  \[
  \begin{aligned}
    E_2 &= 8.4444 \\
    E_3 &= 7.4691 \\
    E_4 &= 7.001 \\
    E_5 &= 6.806 \\
    E_6 &= 6.7247
  \end{aligned}
  \]

  Once you realize that the optimal stopping time is to stop when you get more than 7, then you can calculate the expected value:

  \[
  \mathbb{E}(f(X_T)) = \frac{140}{21} \approx 6.66667
  \]
  Since this is more than 6, the strategy is correct.

\end{itemize}
\end{solution}


\begin{problem}{4.6}
\end{problem}
\begin{solution}
\begin{itemize}
 \item[(a)] 
The algorithm is to find a descending sequence of superharmonics \( u_1, u_2, \ldots \) converging to \( v(x) \), then determine the strategy from this decimal approximation to \( v(x) \) and then from that to determine the precise formula for \( v(x) \). Since this problem is nonstochastic, the value function is determined by its expected value
\[
E = \sum p_x v(x)
\]

We start with the very optimistic function:
\[
u_1 = (0, 36, 36, 36, 36, 36)
\]

This means, if you don’t lose on the first roll, you assume that you will get the highest possible payoff (36). The average of these numbers is
\[
E_1 = (5/6)(36) = 30
\]

\[
u_2(x) = \max(f(x), E_1) = (0, 30, 30, 30, 30, 36)
\]
with average
\[
E_2 = 26
\]

\[
u_3 = (0, 26, 26, 26, 26, 36)
\]
\[
E_3 = 23.3333333, \quad
E_4 = 21.8333333, \quad
E_5 = 21.0833333, \quad
\ldots, \quad
E_{25} = 20.3333369
\]

So, the winning strategy is to stop at 5 or 6 and play at 2, 3, 4. The value function is:
\[
v = (0, E, E, E, 25, 36)
\]

with average:
\[
E = \frac{3E + 25 + 36}{6} = \frac{1}{2}E + \frac{61}{6}
\]

So,
\[
E = \frac{61}{3} = 20\frac{1}{3}
\]

\[
v = (0, 20\frac{1}{3}, 20\frac{1}{3}, 20\frac{1}{3}, 25, 36)
\]

The second question is a little ambiguous since it is not clear exactly what ``expected winnings’’ means. The expected winning of this game is \( E = 20\frac{1}{3} \) before you roll the first die. After you roll and get \( x \), your expected winning is given by \( v(x) \) which depends on \( x \).

 \item[(b)] 
Since you know the optimal strategy, you can skip the first steps and go to the last step. The value function is:
\[
v = (0, E - r, 9, 16, 25, 36)
\]

But \( E - r \) must be \( \leq 9 \), otherwise you should play at \( x = 3 \). So,
\[
r \geq E - 9
\]

The smallest value of \( r \) is when these are equal. So:
\[
v = (0, 9, 9, 16, 25, 36)
\]

with average:
\[
E = \frac{95}{6} = 15\frac{5}{6}
\]

Which makes:
\[
r = E - 9 = 6\frac{5}{6}
\]
\end{itemize}
\end{solution}



\chapter{Martingales}

\begin{problem}{5.1}
\end{problem}
\begin{solution}
\end{solution}



\chapter{Renewal Processes}

\begin{problem}{6.1}
\end{problem}
\begin{solution}
\end{solution}




\chapter{Reversible Markov Chains}

\begin{problem}{7.1}
\end{problem}
\begin{solution}
\end{solution}



\chapter{Brownian Motion}

\begin{problem}{8.1}
\end{problem}
\begin{solution}
\end{solution}





\chapter{Stochastic Integration}


% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------

\end{document}